{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb4e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/argilla/medical-domain/data/train-00000-of-00001-67e4e7207342a623.parquet\")\n",
    "\n",
    "def extract_label(pred):\n",
    "    if isinstance(pred, (list, np.ndarray)) and len(pred) > 0 and isinstance(pred[0], dict):\n",
    "        return pred[0].get(\"label\")\n",
    "    return None\n",
    "\n",
    "df['label'] = df['prediction'].apply(extract_label)\n",
    "df['text_length'] = df['metrics'].apply(lambda x: x.get('text_length') if isinstance(x, dict) else None)\n",
    "\n",
    "# drop empty columns\n",
    "df = df.drop(columns=['inputs', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'multi_label', 'explanation', 'metadata', 'status', 'event_timestamp', 'metrics'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4c114",
   "metadata": {},
   "source": [
    "# 1. Investigate which NER types appear (manual inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa36a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text'].sample(20).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a6c0b",
   "metadata": {},
   "source": [
    "After manually inspecting 20 randomly sampled clinical notes, the following types of named entities appear frequently and consistently throughout the dataset:\n",
    "\n",
    "Core Medical Entity Types\n",
    "1.\tDISEASE / CONDITION: \"fracture\", \"polycythemia vera\", \"pneumonia\", \"multiple sclerosis\", \"otitis media\"\n",
    "\n",
    "2.\tPROCEDURE / SURGERY: \"colonoscopy\", \"laparoscopy\", \"arthroscopy\", \"right middle lobectomy\", \"heart catheterization\"\n",
    "3.\tANATOMY / BODY PART: \"radius and ulna\", \"left shin\", \"rotator cuff\", \"middle lobe\", \"cervical spine\"\n",
    "4.\tMEDICATION: \"methadone\", \"aspirin prophylaxis\", \"prednisone\", \"amoxicillin\", \"Zithromax\"\n",
    "5.\tLAB VALUE / MEASUREMENT: \"CBC 41,900\", \"CRP 6.7\", \"BP 144/85\", \"weight 61.8 kg\", \"temperature 99.5°F\"\n",
    "6.\tSYMPTOM / FINDING: \"pain\", \"swelling\", \"wheezing\", \"fatigue\", \"rash\", \"tenderness\"\n",
    "\n",
    "Conclusion:\n",
    "The dataset is rich in medical terminology, with DISEASE, PROCEDURE, ANATOMY, MEDICATION, LAB_VALUE, and SYMPTOM being the most prominent NER categories. These will be used to define the custom medical NER schema in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79312682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pain': np.int64(2059),\n",
       "         'x-ray': np.int64(698),\n",
       "         'mri': np.int64(529),\n",
       "         'cancer': np.int64(464),\n",
       "         'biopsy': np.int64(437),\n",
       "         'swelling': np.int64(429),\n",
       "         'fracture': np.int64(404),\n",
       "         'ultrasound': np.int64(354),\n",
       "         'ct scan': np.int64(326),\n",
       "         'tumor': np.int64(325),\n",
       "         'aspirin': np.int64(315),\n",
       "         'pneumonia': np.int64(223),\n",
       "         'colonoscopy': np.int64(156),\n",
       "         'laparoscopy': np.int64(76),\n",
       "         'methadone': np.int64(32)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantitative support to manual inspection\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "keywords = [\"fracture\", \"pneumonia\", \"colonoscopy\", \"laparoscopy\", \"methadone\", \"aspirin\", \"pain\", \"swelling\",\"biopsy\", \"ultrasound\", \"mri\", \"ct scan\", \"x-ray\", \"tumor\", \"cancer\"]\n",
    "Counter({kw: df['text'].str.contains(kw, case=False).sum() for kw in keywords})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d34cc",
   "metadata": {},
   "source": [
    "# 2. Apply spaCy’s standard NER classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b050a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4966/4966 [01:47<00:00, 46.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER processing took 107.90 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import subprocess\n",
    "import sys\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "model_name = \"en_core_web_md\"\n",
    "try:\n",
    "    nlp = spacy.load(model_name)\n",
    "except OSError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", model_name])\n",
    "    nlp = spacy.load(model_name)\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "start_time = time.time()\n",
    "ents_list = []\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=32, n_process=multiprocessing.cpu_count()), total=len(texts)):\n",
    "    ents_list.append([(ent.text, ent.label_) for ent in doc.ents])\n",
    "end_time = time.time()\n",
    "print(f\"NER processing took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "df['spacy_ents'] = ents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570953c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacy_ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Iron deficiency anemia.,POSTOPERATIVE DIAGNOSIS:,  Diverticulosis.,PROCEDURE:,  Colonoscopy.,MEDICATIONS: , MAC.,PROCEDURE: , The Olympus pediatric variable colonoscope w...</td>\n",
       "      <td>[(Iron, ORG), (Diverticulosis, PERSON), (Colonoscopy, ORG), (MAC.,PROCEDURE, GPE), (Olympus, ORG), (retroflex, NORP), (Diverticulosis, PERSON), (2 years, DATE)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLINICAL INDICATION:  ,Normal stress test.,PROCEDURES PERFORMED:,1.  Left heart cath.,2.  Selective coronary angiography.,3.  LV gram.,4.  Right femoral arteriogram.,5.  Mynx closure device.,PROCE...</td>\n",
       "      <td>[(LV gram, PERSON), (Mynx, ORG), (2%, PERCENT), (6-French, QUANTITY), (6-French JL4, MONEY), (6-French 3DRC, QUANTITY), (6-French, QUANTITY), (Post LV gram, FAC), (Mynx, ORG), (LVEDP, ORG), (9, DA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FINDINGS:,Axial scans were performed from L1 to S2 and reformatted images were obtained in the sagittal and coronal planes.,Preliminary scout film demonstrates anterior end plate spondylosis at T1...</td>\n",
       "      <td>[(L1 to S2, FAC), (T11-12, ORG), (T12-L1.,L1-2, ORG), (4.6mm, QUANTITY), (AP, ORG), (#25).,L4-5, MONEY)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Blood loss anemia.,POSTOPERATIVE DIAGNOSES:,1.  Diverticulosis coli.,2.  Internal hemorrhoids.,3.  Poor prep.,PROCEDURE PERFORMED:,  Colonoscopy with photos.,ANESTHESIA: ...</td>\n",
       "      <td>[(DIAGNOSES:,1, ORG), (Diverticulosis, PERSON), (Conscious, ORG), (Anesthesia, PERSON), (85-year-old, DATE), (EGD, ORG), (the Endoscopy Suite, ORG), (the Anesthesia Department, ORG)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REASON FOR VISIT:  ,Elevated PSA with nocturia and occasional daytime frequency.,HISTORY: , A 68-year-old male with a history of frequency and some outlet obstructive issues along with irritative ...</td>\n",
       "      <td>[(nocturia, ORG), (68-year-old, DATE), (PSA, ORG), (PSA, ORG), (2004, DATE), (5.5, DATE), (2003, DATE), (Dr. X, PERSON), (1.6, CARDINAL), (Proscar, PERSON), (Proscar, PERSON), (greater than five y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  PREOPERATIVE DIAGNOSIS:,  Iron deficiency anemia.,POSTOPERATIVE DIAGNOSIS:,  Diverticulosis.,PROCEDURE:,  Colonoscopy.,MEDICATIONS: , MAC.,PROCEDURE: , The Olympus pediatric variable colonoscope w...   \n",
       "1  CLINICAL INDICATION:  ,Normal stress test.,PROCEDURES PERFORMED:,1.  Left heart cath.,2.  Selective coronary angiography.,3.  LV gram.,4.  Right femoral arteriogram.,5.  Mynx closure device.,PROCE...   \n",
       "2  FINDINGS:,Axial scans were performed from L1 to S2 and reformatted images were obtained in the sagittal and coronal planes.,Preliminary scout film demonstrates anterior end plate spondylosis at T1...   \n",
       "3  PREOPERATIVE DIAGNOSIS: , Blood loss anemia.,POSTOPERATIVE DIAGNOSES:,1.  Diverticulosis coli.,2.  Internal hemorrhoids.,3.  Poor prep.,PROCEDURE PERFORMED:,  Colonoscopy with photos.,ANESTHESIA: ...   \n",
       "4  REASON FOR VISIT:  ,Elevated PSA with nocturia and occasional daytime frequency.,HISTORY: , A 68-year-old male with a history of frequency and some outlet obstructive issues along with irritative ...   \n",
       "\n",
       "                                                                                                                                                                                                spacy_ents  \n",
       "0                                         [(Iron, ORG), (Diverticulosis, PERSON), (Colonoscopy, ORG), (MAC.,PROCEDURE, GPE), (Olympus, ORG), (retroflex, NORP), (Diverticulosis, PERSON), (2 years, DATE)]  \n",
       "1  [(LV gram, PERSON), (Mynx, ORG), (2%, PERCENT), (6-French, QUANTITY), (6-French JL4, MONEY), (6-French 3DRC, QUANTITY), (6-French, QUANTITY), (Post LV gram, FAC), (Mynx, ORG), (LVEDP, ORG), (9, DA...  \n",
       "2                                                                                                 [(L1 to S2, FAC), (T11-12, ORG), (T12-L1.,L1-2, ORG), (4.6mm, QUANTITY), (AP, ORG), (#25).,L4-5, MONEY)]  \n",
       "3                   [(DIAGNOSES:,1, ORG), (Diverticulosis, PERSON), (Conscious, ORG), (Anesthesia, PERSON), (85-year-old, DATE), (EGD, ORG), (the Endoscopy Suite, ORG), (the Anesthesia Department, ORG)]  \n",
       "4  [(nocturia, ORG), (68-year-old, DATE), (PSA, ORG), (PSA, ORG), (2004, DATE), (5.5, DATE), (2003, DATE), (Dr. X, PERSON), (1.6, CARDINAL), (Proscar, PERSON), (Proscar, PERSON), (greater than five y...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'spacy_ents']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81543ca7",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "spaCy's general English model is not specialized for clinical NER tasks. For example, \"Iron\" -> ORG, \"Diverticulosis\" -> PERSON, \"Colonoscopy\" -> ORG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52153540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ORG', 31211),\n",
       " ('CARDINAL', 28793),\n",
       " ('DATE', 19170),\n",
       " ('PERSON', 15137),\n",
       " ('QUANTITY', 10040),\n",
       " ('GPE', 4631),\n",
       " ('TIME', 4325),\n",
       " ('PRODUCT', 3739),\n",
       " ('ORDINAL', 3462),\n",
       " ('PERCENT', 3192),\n",
       " ('NORP', 2729),\n",
       " ('MONEY', 2283),\n",
       " ('LOC', 595),\n",
       " ('FAC', 540),\n",
       " ('LAW', 371),\n",
       " ('EVENT', 308),\n",
       " ('WORK_OF_ART', 194),\n",
       " ('LANGUAGE', 84)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute entity frequencies\n",
    "from collections import Counter\n",
    "\n",
    "ent_counter = Counter()\n",
    "for ents in df['spacy_ents']:\n",
    "    for _, label in ents:\n",
    "        ent_counter[label] += 1\n",
    "\n",
    "ent_counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79907d",
   "metadata": {},
   "source": [
    "# 3. Evaluate spaCy NER (automatic + manual)\n",
    "\n",
    "### 3.1 Manual Evaluation of spaCy NER (100 Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "187092e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacy_ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>[(16-year-old, DATE), (the Pediatric Endocrinology Department, ORG), (first, ORDINAL), (about 2004, DATE), (the Pediatric Endocrinology Department, ORG), (zero, CARDINAL), (Tijuana, GPE), (Mexico,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>[(25 mg, QUANTITY), (Demerol, ORG), (the IV Demerol, ORG), (25 mg, QUANTITY), (Phenergan IV, GPE), (7.5 mg, QUANTITY), (Digital, ORG), (P160, PRODUCT), (30 cm, QUANTITY), (five, CARDINAL), (One, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>[(Esophagogastroduodenoscopy, ORG), (Melena, PERSON), (GI, ORG), (IMPRESSION,1, ORG), (Repeat EGD, PERSON), (tomorrow, DATE), (morning, TIME), (ICU, ORG), (100, CARDINAL), (EGD, ORG), (An addition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>[(35-year-old, DATE), (the 30th of October 2008, DATE), (nine months, DATE), (approximately 14 to 18 hours, DATE), (the 31st of October, DATE), (Foley, PERSON), (the 1st of November 2008, DATE), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>[(Bronchoscopy, ORG), (Foley, PERSON), (Betadine, NORP), (Hemostasis, PERSON), (sixth, ORDINAL), (sixth, ORDINAL), (3 cm, QUANTITY), (#00, MONEY), (Potts, PERSON), (Direction, FAC), (000, MONEY), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                   spacy_ents\n",
       "3138  [(16-year-old, DATE), (the Pediatric Endocrinology Department, ORG), (first, ORDINAL), (about 2004, DATE), (the Pediatric Endocrinology Department, ORG), (zero, CARDINAL), (Tijuana, GPE), (Mexico,...\n",
       "1964  [(25 mg, QUANTITY), (Demerol, ORG), (the IV Demerol, ORG), (25 mg, QUANTITY), (Phenergan IV, GPE), (7.5 mg, QUANTITY), (Digital, ORG), (P160, PRODUCT), (30 cm, QUANTITY), (five, CARDINAL), (One, C...\n",
       "1344  [(Esophagogastroduodenoscopy, ORG), (Melena, PERSON), (GI, ORG), (IMPRESSION,1, ORG), (Repeat EGD, PERSON), (tomorrow, DATE), (morning, TIME), (ICU, ORG), (100, CARDINAL), (EGD, ORG), (An addition...\n",
       "2984  [(35-year-old, DATE), (the 30th of October 2008, DATE), (nine months, DATE), (approximately 14 to 18 hours, DATE), (the 31st of October, DATE), (Foley, PERSON), (the 1st of November 2008, DATE), (...\n",
       "4910  [(Bronchoscopy, ORG), (Foley, PERSON), (Betadine, NORP), (Hemostasis, PERSON), (sixth, ORDINAL), (sixth, ORDINAL), (3 cm, QUANTITY), (#00, MONEY), (Potts, PERSON), (Direction, FAC), (000, MONEY), ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(100, random_state=42)\n",
    "sample_df[['spacy_ents']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bd777",
   "metadata": {},
   "source": [
    "We sampled 100 random entities from the model output and evaluated whether each prediction is correct in the medical context.\n",
    "\n",
    "| Entity | spaCy Label | Correct? | Expected Medical Category | Comment |\n",
    "|--------|-------------|----------|----------------------------|---------|\n",
    "| Esophagogastroduodenoscopy | ORG | ❌ | PROCEDURE | Misread as organization |\n",
    "| Melena | PERSON | ❌ | SYMPTOM / FINDING | Disease labeled as person |\n",
    "| Demerol | ORG | ❌ | MEDICATION | Drug interpreted as an organization |\n",
    "| Betadine | NORP | ❌ | MEDICATION / ANTISEPTIC | Not a nationality/group |\n",
    "| CT Abdomen & Pelvis | ORG | ❌ | IMAGING PROCEDURE | Imaging test mislabeled |\n",
    "| Foley | PERSON | ❌ | DEVICE / CATHETER | Mistaken as a person |\n",
    "| L4–L5 | ORG | ❌ | ANATOMY | Vertebral level mislabeled |\n",
    "| 3.4 cm | QUANTITY | ✔️ | MEASUREMENT | Correct |\n",
    "| 12-mm trocar | QUANTITY | ✔️ | DEVICE SIZE | Acceptable |\n",
    "| 05/26/1999 | DATE | ✔️ | DATE | Correct |\n",
    "| Pediatric Endocrinology Dept | ORG | ✔️ | DEPARTMENT | Acceptable |\n",
    "| Tijuana | GPE | ✔️ | LOCATION | Correct |\n",
    "| Isovue-300 | LOC | ❌ | CONTRAST AGENT | Incorrect category |\n",
    "| ICU | ORG | ❌ | LOCATION / UNIT | Hospital units ≠ organizations |\n",
    "| Bronchoscopy | ORG | ❌ | PROCEDURE | Misread as organization |\n",
    "| Hemostasis | PERSON | ❌ | PROCEDURE / ACTION | Labeled as a person |\n",
    "| Potts | PERSON | ✔️ | SURGICAL INSTRUMENT | Label acceptable but misleading |\n",
    "| 100 mL | QUANTITY | ✔️ | DOSAGE/VOLUME | Correct |\n",
    "| 2.5 cm | QUANTITY | ✔️ | MEASUREMENT | Correct |\n",
    "| hemiscrotum | ORG | ❌ | ANATOMY | Body part labeled as ORG |\n",
    "| Electrocautery | PERSON | ❌ | PROCEDURE / DEVICE | Not a person |\n",
    "| 1.72 | CARDINAL | ✔️ | NUMERIC VALUE | OK |\n",
    "| Soft | PERSON | ❌ | EXAM FINDING | Not a person |\n",
    "| Hydrochlorothiazide | ORG | ❌ | MEDICATION | Drug mislabeled |\n",
    "| Lisinopril | ORG | ❌ | MEDICATION | Drug mislabeled |\n",
    "| Percocet | ORG | ❌ | MEDICATION | Drug mislabeled |\n",
    "| Nontender | PERSON | ❌ | EXAM FINDING | Not a person |\n",
    "| Marcaine | PERSON | ❌ | MEDICATION | Not a person |\n",
    "| Veress | PRODUCT | ✔️ | SURGICAL DEVICE | Acceptable |\n",
    "| 12-mm VersaStep | QUANTITY | ✔️ | DEVICE SIZE | OK |\n",
    "| Appendix | NORP | ❌ | ANATOMY | Not a nationality |\n",
    "| Endocatch | ORG | ❌ | SURGICAL DEVICE | Incorrect |\n",
    "| ABCD General Hospital | ORG | ✔️ | FACILITY | Correct |\n",
    "| X. | PERSON | ✔️ | PERSON | Correct |\n",
    "| 1% | PERCENT | ✔️ | MEASUREMENT | Correct |\n",
    "| Glenn | PERSON | ✔️ | PERSON/PROCEDURE | Acceptable |\n",
    "| Fontan | PERSON | ❌ | PROCEDURE | Misinterpreted as person |\n",
    "| Benadryl | ORG | ❌ | MEDICATION | Drug mislabeled |\n",
    "| 124 pounds | QUANTITY | ✔️ | WEIGHT | Correct |\n",
    "| 96/54 | CARDINAL | ✔️ | VITAL SIGN | spaCy lacks medical category |\n",
    "| Phacoemulsification | ORG | ❌ | PROCEDURE | Incorrect |\n",
    "| Silicone | ORG | ❌ | MATERIAL | Incorrect |\n",
    "| ABC Laboratories | ORG | ✔️ | COMPANY | Correct |\n",
    "| EKG | ORG | ❌ | PROCEDURE | Misclassified |\n",
    "| Jun. | PERSON | ❌ | DATE | Misread as a person |\n",
    "| Laparoscopic Roux-en-Y | PERSON | ❌ | PROCEDURE | Wrong label |\n",
    "| EEA | ORG | ❌ | SURGICAL DEVICE | Incorrect |\n",
    "| Ziac | PERSON | ❌ | MEDICATION | Wrong label |\n",
    "| Remeron | PERSON | ❌ | MEDICATION | Wrong label |\n",
    "| Salt Lake City | GPE | ✔️ | LOCATION | Correct |\n",
    "| Noncontrast CT | ORG | ❌ | IMAGING PROCEDURE | Incorrect |\n",
    "| Levaquin | PERSON | ❌ | MEDICATION | Incorrect |\n",
    "| Reglan | FAC | ❌ | MEDICATION | Incorrect |\n",
    "| Streptococcal | ORG | ❌ | DISEASE / ORGANISM | Incorrect |\n",
    "| thromboplastin | NORP | ❌ | LAB / PROTEIN | Not nationality |\n",
    "| Foley catheter | PERSON | ❌ | DEVICE | Wrong label |\n",
    "| Veress needle | PRODUCT | ✔️ | DEVICE | Correct |\n",
    "| 16-French | QUANTITY | ✔️ | DEVICE SIZE | Correct |\n",
    "| concha bullosa | PERSON | ❌ | ANATOMICAL FINDING | Wrong label |\n",
    "| ENT | ORG | ✔️ | SPECIALTY | Acceptable |\n",
    "| CT Abdomen & Pelvis W/WO | ORG | ❌ | IMAGING | Incorrect |\n",
    "| Powerade | PERSON | ❌ | SUBSTANCE | Not a person |\n",
    "| CPK | ORG | ❌ | LAB TEST | Incorrect |\n",
    "| Kawasaki | PERSON | ❌ | DISEASE | Wrong |\n",
    "| CRP | ORG | ❌ | LAB TEST | Wrong |\n",
    "| ESR | ORG | ❌ | LAB TEST | Wrong |\n",
    "| IVIG | ORG | ❌ | MEDICATION / IMMUNOTHERAPY | Wrong |\n",
    "| Echocardiogram | ORG | ❌ | IMAGING PROCEDURE | Wrong |\n",
    "| SMK | ORG | ✔️ | COMPANY / BRAND | Acceptable |\n",
    "| Depo-Medrol | PRODUCT | ✔️ | MEDICATION | Acceptable |\n",
    "| Coagulation | ORG | ❌ | LAB / PHYSIOLOGY | Wrong |\n",
    "| ERCP | ORG | ❌ | PROCEDURE | Wrong |\n",
    "| Medical Oncology | ORG | ✔️ | DEPARTMENT | Acceptable |\n",
    "| T7–T8 | PRODUCT | ❌ | ANATOMY | Wrong category |\n",
    "| Medtronic | ORG | ✔️ | DEVICE COMPANY | Correct |\n",
    "| Fluoroscopy | PERSON | ❌ | IMAGING PROCEDURE | Wrong |\n",
    "| T2–L2 | NORP | ❌ | ANATOMY | Not a nationality |\n",
    "| Jackson | PERSON | ✔️ | PERSON | Correct |\n",
    "| Thecal sac | ORG | ❌ | ANATOMY | Wrong |\n",
    "| 5.5 | CARDINAL | ✔️ | VALUE | Correct |\n",
    "| 20 mg | QUANTITY | ✔️ | DOSAGE | Correct |\n",
    "| 30 cm | QUANTITY | ✔️ | MEASUREMENT | Correct |\n",
    "| One | CARDINAL | ✔️ | NUMBER | Correct |\n",
    "| 000 | MONEY | ❌ | NONE | Misinterpreted as money |\n",
    "| Direction | FAC | ❌ | NONE | Wrong label |\n",
    "| Soft tissue | PERSON | ❌ | ANATOMY | Misinterpreted |\n",
    "| Renal | ORG | ❌ | ANATOMY / ADJECTIVE | Incorrect |\n",
    "| 47-year-old | DATE | ❌ | AGE | Age ≠ Date |\n",
    "| daily | DATE | ❌ | FREQUENCY | Not a date |\n",
    "| five days | DATE | ✔️ | TEMPORAL | Acceptable |\n",
    "| Appendectomy | ORG | ❌ | PROCEDURE | Wrong |\n",
    "| Benign tumor | ORG | ❌ | DIAGNOSIS | Wrong |\n",
    "| L5-S1 | ORG | ❌ | ANATOMY | Wrong |\n",
    "| Marcaine injection | PERSON | ❌ | PROCEDURE | Wrong |\n",
    "| Hemostasis achieved | PERSON | ❌ | PROCEDURE STEP | Wrong |\n",
    "| 10 cm incision | QUANTITY | ✔️ | MEASUREMENT | Correct |\n",
    "| 200 mg | QUANTITY | ✔️ | DOSAGE | Correct |\n",
    "| 50-year-old | DATE | ❌ | AGE | Wrong label |\n",
    "| Many years | DATE | ✔️ | TEMPORAL | Correct |\n",
    "| 14 months | DATE | ✔️ | AGE | Acceptable |\n",
    "\n",
    "**What spaCy Does Well**\n",
    "- Dates and temporal expressions (e.g., “05/26/1999”, “five days”)\n",
    "- Quantities and measurements (cm, mg, %, weights)\n",
    "- Person names (e.g., \"Jackson\")\n",
    "- Some organizations and locations\n",
    "\n",
    "**What spaCy Does Poorly**\n",
    "- Medications often -> ORG or PERSON  \n",
    "- Procedures often -> ORG  \n",
    "- Anatomy -> ORG, NORP, or PERSON  \n",
    "- Devices -> PERSON  \n",
    "- Lab tests -> ORG  \n",
    "- Diseases -> PERSON  \n",
    "- No medical categories (MEDICATION, PROCEDURE, ANATOMY, LAB, etc.)\n",
    "\n",
    "**Overall Quality (100 entities)**\n",
    "- Correct: ~30%\n",
    "- Incorrect: ~70%\n",
    "\n",
    "spaCy’s general English model performs poorly on clinical notes.\n",
    "It lacks domain knowledge and mislabels most medical entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd0601",
   "metadata": {},
   "source": [
    "### 3.2 Automatic Evaluation\n",
    "\n",
    "Since we do not have gold standard NER annotations, we cannot do automatic evaluation like precision/recall/F1. Custom annotations will be created in the next steps for proper evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c832ac",
   "metadata": {},
   "source": [
    "# 4. Extend NER with custom entity types (NER Annotator)\n",
    "\n",
    "To overcome the limitations of spaCy’s general-purpose NER model on clinical text, we created a custom medical NER system using six domain-specific labels:\n",
    "\n",
    "DISEASE, MEDICATION, SYMPTOM, PROCEDURE, ANATOMY, LAB_VALUE\n",
    "\n",
    "### 4.1 Manual Annotation Using NER Annotator\n",
    "\n",
    "We manually annotated clinical reports using the online NER Annotator tool. https://arunmozhi.in/ner-annotator/\n",
    "\n",
    "The resulting annotations.json file contains:\n",
    "- ~12 annotated documents\n",
    "- Several thousand labeled entities across all classes\n",
    "- Clean character-based spans compatible with spaCy\n",
    "\n",
    "Example annotation:\n",
    "```json\n",
    "{\n",
    "  \"classes\": [\"DISEASE\", \"MEDICATION\", \"SYMPTOM\", ...],\n",
    "  \"annotations\": [\n",
    "    [\"<text 1>\", {\"entities\": [[start, end, label], ...]}],\n",
    "    [\"<text 2>\", {\"entities\": [...]}],\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbb0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = df['text'].sample(10, random_state=42)\n",
    "sample_texts.to_csv('../data/samples/to_annotate.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df719aa",
   "metadata": {},
   "source": [
    "### 4.2 Converting JSON to spaCy’s DocBin Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f0e7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.ner import train_custom_ner, load_annotated_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3cb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this JSON into spaCy’s DocBin format:\n",
    "db = load_annotated_json(\"../data/annotated/annotations.json\")\n",
    "db.to_disk(\"train.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e824c01",
   "metadata": {},
   "source": [
    "### 4.2 Training the Custom NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b8264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Losses: {'ner': np.float32(7577.8975)}\n",
      "Iteration 2, Losses: {'ner': np.float32(7022.537)}\n",
      "Iteration 3, Losses: {'ner': np.float32(3943.5583)}\n",
      "Iteration 4, Losses: {'ner': np.float32(1503.7443)}\n",
      "Iteration 5, Losses: {'ner': np.float32(1403.2487)}\n",
      "Iteration 6, Losses: {'ner': np.float32(1320.5245)}\n",
      "Iteration 7, Losses: {'ner': np.float32(1162.0874)}\n",
      "Iteration 8, Losses: {'ner': np.float32(1173.6781)}\n",
      "Iteration 9, Losses: {'ner': np.float32(1084.098)}\n",
      "Iteration 10, Losses: {'ner': np.float32(1077.1304)}\n",
      "Iteration 11, Losses: {'ner': np.float32(1012.0186)}\n",
      "Iteration 12, Losses: {'ner': np.float32(969.8941)}\n",
      "Iteration 13, Losses: {'ner': np.float32(942.35364)}\n",
      "Iteration 14, Losses: {'ner': np.float32(900.80725)}\n",
      "Iteration 15, Losses: {'ner': np.float32(848.2076)}\n",
      "Iteration 16, Losses: {'ner': np.float32(799.437)}\n",
      "Iteration 17, Losses: {'ner': np.float32(794.9763)}\n",
      "Iteration 18, Losses: {'ner': np.float32(756.0616)}\n",
      "Iteration 19, Losses: {'ner': np.float32(736.13043)}\n",
      "Iteration 20, Losses: {'ner': np.float32(716.8009)}\n",
      "Iteration 21, Losses: {'ner': np.float32(697.20953)}\n",
      "Iteration 22, Losses: {'ner': np.float32(668.97986)}\n",
      "Iteration 23, Losses: {'ner': np.float32(619.716)}\n",
      "Iteration 24, Losses: {'ner': np.float32(614.8642)}\n",
      "Iteration 25, Losses: {'ner': np.float32(586.04333)}\n",
      "Iteration 26, Losses: {'ner': np.float32(563.5461)}\n",
      "Iteration 27, Losses: {'ner': np.float32(526.48987)}\n",
      "Iteration 28, Losses: {'ner': np.float32(508.54755)}\n",
      "Iteration 29, Losses: {'ner': np.float32(471.9659)}\n",
      "Iteration 30, Losses: {'ner': np.float32(440.62045)}\n",
      "Saved model at: ../data/models/custom_ner\n"
     ]
    }
   ],
   "source": [
    "# 6 custom labels and train a blank eglish model from scratch\n",
    "labels = [\"DISEASE\", \"MEDICATION\", \"SYMPTOM\", \"PROCEDURE\", \"ANATOMY\", \"LAB_VALUE\"]\n",
    "\n",
    "output_dir = \"../data/models/custom_ner\"\n",
    "\n",
    "nlp_custom = train_custom_ner(\"train.spacy\",output_dir, labels, n_iter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4eca0c",
   "metadata": {},
   "source": [
    "### 4.4 Applying the Custom Model to All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7d9bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4966/4966 [00:41<00:00, 120.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER processing time: 41.29432010650635 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import time\n",
    "\n",
    "nlp_custom = spacy.load(\"../data/models/custom_ner\")\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "start_time = time.time()\n",
    "ents_list = []\n",
    "for doc in tqdm(nlp_custom.pipe(texts, batch_size=32, n_process=multiprocessing.cpu_count()), total=len(texts)):\n",
    "    ents_list.append([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"NER processing time: {end_time - start_time} seconds\")\n",
    "df['custom_ents'] = ents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89bec9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ANATOMY', 68662),\n",
       " ('PROCEDURE', 48211),\n",
       " ('DISEASE', 28924),\n",
       " ('MEDICATION', 3168),\n",
       " ('LAB_VALUE', 2904),\n",
       " ('SYMPTOM', 1861)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute entity frequencies\n",
    "from collections import Counter\n",
    "\n",
    "ent_counter = Counter()\n",
    "for ents in df['custom_ents']:\n",
    "    for _, label in ents:\n",
    "        ent_counter[label] += 1\n",
    "\n",
    "ent_counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2f261",
   "metadata": {},
   "source": [
    "**Note**\n",
    "- surgical and radiology notes have a lot of ANATOMY and PROCEDURE entities.\n",
    "- MEDICATION is comparatively rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39e89de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>custom_ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>REASON FOR CONSULTATION: , Thyroid mass diagnosed as papillary carcinoma.,HISTORY OF PRESENT ILLNESS:  ,The patient is a 16-year-old young lady, who was referred from the Pediatric Endocrinology D...</td>\n",
       "      <td>[(Thyroid, ANATOMY), (papillary carcinoma, DISEASE), (thyroid, ANATOMY), (papillary carcinoma, ANATOMY), (thyroid, ANATOMY), (papillary thyroid, ANATOMY), (hypothyroidism, DISEASE), (thyroid cance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Prior history of neoplastic polyps.,POSTOPERATIVE DIAGNOSIS:,  Small rectal polyps/removed and fulgurated.,PREMEDICATIONS:,  Prior to the colonoscopy, the patient complai...</td>\n",
       "      <td>[(neoplastic polyps, DISEASE), (rectal polyps, DISEASE), (colonoscopy, ANATOMY), (headache, DISEASE), (25 mg, LAB_VALUE), (Demerol, MEDICATION), (Demerol, MEDICATION), (nausea, MEDICATION), (Phene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>PROCEDURE PERFORMED: , Esophagogastroduodenoscopy performed in the emergency department.,INDICATION: , Melena, acute upper GI bleed, anemia, and history of cirrhosis and varices.,FINAL IMPRESSION,...</td>\n",
       "      <td>[(Esophagogastroduodenoscopy, ANATOMY), (Melena, DISEASE), (acute upper GI bleed, ANATOMY), (anemia, DISEASE), (cirrhosis, DISEASE), (varices, DISEASE), (stomach, ANATOMY), (fundus, ANATOMY), (End...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , The patient is a 35-year-old woman who reports that on the 30th of October 2008, she had a rupture of her membranes at nine months of pregnancy, and was admitted to h...</td>\n",
       "      <td>[(epidural anesthetic, MEDICATION), (epidural, ANATOMY), (14 to 18 hours, LAB_VALUE), (epidural, ANATOMY), (epidural, ANATOMY), (delivered, ANATOMY), (Cesarean section, PROCEDURE), (failed, MEDICA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:  ,Carcinoma of the left upper lobe.,PROCEDURES PERFORMED:,1.  Bronchoscopy with aspiration.,2.  Left upper lobectomy.,PROCEDURE DETAILS:  ,With patient in supine position u...</td>\n",
       "      <td>[(Carcinoma, ANATOMY), (left upper, ANATOMY), (Bronchoscopy, ANATOMY), (aspiration, PROCEDURE), (Left upper lobectomy, PROCEDURE), (placed, ANATOMY), (examine, ANATOMY), (carina, ANATOMY), (carina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         text  \\\n",
       "3138  REASON FOR CONSULTATION: , Thyroid mass diagnosed as papillary carcinoma.,HISTORY OF PRESENT ILLNESS:  ,The patient is a 16-year-old young lady, who was referred from the Pediatric Endocrinology D...   \n",
       "1964  PREOPERATIVE DIAGNOSIS:,  Prior history of neoplastic polyps.,POSTOPERATIVE DIAGNOSIS:,  Small rectal polyps/removed and fulgurated.,PREMEDICATIONS:,  Prior to the colonoscopy, the patient complai...   \n",
       "1344  PROCEDURE PERFORMED: , Esophagogastroduodenoscopy performed in the emergency department.,INDICATION: , Melena, acute upper GI bleed, anemia, and history of cirrhosis and varices.,FINAL IMPRESSION,...   \n",
       "2984  HISTORY OF PRESENT ILLNESS: , The patient is a 35-year-old woman who reports that on the 30th of October 2008, she had a rupture of her membranes at nine months of pregnancy, and was admitted to h...   \n",
       "4910  PREOPERATIVE DIAGNOSIS:  ,Carcinoma of the left upper lobe.,PROCEDURES PERFORMED:,1.  Bronchoscopy with aspiration.,2.  Left upper lobectomy.,PROCEDURE DETAILS:  ,With patient in supine position u...   \n",
       "\n",
       "                                                                                                                                                                                                  custom_ents  \n",
       "3138  [(Thyroid, ANATOMY), (papillary carcinoma, DISEASE), (thyroid, ANATOMY), (papillary carcinoma, ANATOMY), (thyroid, ANATOMY), (papillary thyroid, ANATOMY), (hypothyroidism, DISEASE), (thyroid cance...  \n",
       "1964  [(neoplastic polyps, DISEASE), (rectal polyps, DISEASE), (colonoscopy, ANATOMY), (headache, DISEASE), (25 mg, LAB_VALUE), (Demerol, MEDICATION), (Demerol, MEDICATION), (nausea, MEDICATION), (Phene...  \n",
       "1344  [(Esophagogastroduodenoscopy, ANATOMY), (Melena, DISEASE), (acute upper GI bleed, ANATOMY), (anemia, DISEASE), (cirrhosis, DISEASE), (varices, DISEASE), (stomach, ANATOMY), (fundus, ANATOMY), (End...  \n",
       "2984  [(epidural anesthetic, MEDICATION), (epidural, ANATOMY), (14 to 18 hours, LAB_VALUE), (epidural, ANATOMY), (epidural, ANATOMY), (delivered, ANATOMY), (Cesarean section, PROCEDURE), (failed, MEDICA...  \n",
       "4910  [(Carcinoma, ANATOMY), (left upper, ANATOMY), (Bronchoscopy, ANATOMY), (aspiration, PROCEDURE), (Left upper lobectomy, PROCEDURE), (placed, ANATOMY), (examine, ANATOMY), (carina, ANATOMY), (carina...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(100, random_state=42)\n",
    "sample_df[['text', 'custom_ents']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ade6d8",
   "metadata": {},
   "source": [
    "### 4.5 Evaluate 100 random custom entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ddbd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dissection</td>\n",
       "      <td>PROCEDURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exchange</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heart</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bleeding</td>\n",
       "      <td>PROCEDURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knee arthroplasty</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Behavioral Health</td>\n",
       "      <td>PROCEDURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>removed</td>\n",
       "      <td>PROCEDURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>legs</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subcutaneous tissue</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11 days</td>\n",
       "      <td>LAB_VALUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>layers</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edema</td>\n",
       "      <td>DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cord</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lateral aspect</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>muscle</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cecum</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>potassium</td>\n",
       "      <td>PROCEDURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fever</td>\n",
       "      <td>PROCEDURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>#11 port</td>\n",
       "      <td>LAB_VALUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>uvula</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 entity      label\n",
       "0            dissection  PROCEDURE\n",
       "1              exchange    ANATOMY\n",
       "2                 heart    ANATOMY\n",
       "3              bleeding  PROCEDURE\n",
       "4     knee arthroplasty    ANATOMY\n",
       "5     Behavioral Health  PROCEDURE\n",
       "6               removed  PROCEDURE\n",
       "7                  legs    ANATOMY\n",
       "8   subcutaneous tissue    ANATOMY\n",
       "9               11 days  LAB_VALUE\n",
       "10               layers    ANATOMY\n",
       "11                edema    DISEASE\n",
       "12                 cord    ANATOMY\n",
       "13       lateral aspect    ANATOMY\n",
       "14               muscle    ANATOMY\n",
       "15                cecum    ANATOMY\n",
       "16            potassium  PROCEDURE\n",
       "17                fever  PROCEDURE\n",
       "18             #11 port  LAB_VALUE\n",
       "19                uvula    ANATOMY"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "all_custom_ents = []\n",
    "for ents in df[\"custom_ents\"]:\n",
    "    all_custom_ents.extend(ents)\n",
    "\n",
    "sample_ents = random.sample(all_custom_ents, 100)\n",
    "\n",
    "eval_df = pd.DataFrame(sample_ents, columns=[\"entity\", \"label\"])\n",
    "\n",
    "# To save for manual evaluation\n",
    "# eval_df.to_csv(\"../data/custom_ner_evaluation/custom_ner_manual_to_eval.csv\", index=False)\n",
    "# eval_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81a6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------\n",
      "Entity: dissection\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: exchange\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: heart\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: bleeding\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: knee arthroplasty\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Behavioral Health\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: removed\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: legs\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: subcutaneous tissue\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: 11 days\n",
      "Label : LAB_VALUE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: layers\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: edema\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: cord\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: lateral aspect\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: muscle\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: cecum\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: potassium\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: fever\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: #11 port\n",
      "Label : LAB_VALUE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: uvula\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: pain\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: chloride\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: 28\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: carina\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: laparotomy\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: removed\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: feedings\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: heart\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Gelfoam\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: muscles\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: #2 Miller\n",
      "Label : LAB_VALUE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: epidural space\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: mouth\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: T4\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: removed\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: peri\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: aortic valve\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: provided\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: photophobia\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: placed\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: barium swallow\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: surgery\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: abdomen\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Urinary tract infection\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: medial border\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: sedation\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: aortic arch\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: stenosis\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: left atrium\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: tubes\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: bleeding\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Closed head\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: procedure\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: anemia\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: electrocautery\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: 6 x 2 cm\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: chest pain\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: spine\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: neuroforamina\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: placed\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: recurrence\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Cervical carcinoma\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: pacing\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: same distribution\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: infection\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: kidney\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Ears\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: hepatitis\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: probe\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: right foot\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Bilateral tibial motor\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: cord\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: CaCO3\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: extubated\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Dilatation\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: penicillin\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: erythema\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: closed\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: needle\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: 6-0 plain\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: injection\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: #18 gauge\n",
      "Label : LAB_VALUE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: preserved\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: 2/19/96\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: probiotic's\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: procedure\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: lesion\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: aortic pressure\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: skin\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: musculature\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: 65%\n",
      "Label : LAB_VALUE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: progressive desaturation\n",
      "Label : DISEASE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: discomfort\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: Respirations\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: dissection\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: AST\n",
      "Label : SYMPTOM\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: rhythm\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: placed\n",
      "Label : PROCEDURE\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: lateral pedicles\n",
      "Label : ANATOMY\n",
      "\n",
      "--------------------------------------------\n",
      "Entity: chills\n",
      "Label : PROCEDURE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dissection</td>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exchange</td>\n",
       "      <td>ANATOMY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heart</td>\n",
       "      <td>ANATOMY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bleeding</td>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knee arthroplasty</td>\n",
       "      <td>ANATOMY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AST</td>\n",
       "      <td>SYMPTOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>rhythm</td>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>placed</td>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>lateral pedicles</td>\n",
       "      <td>ANATOMY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>chills</td>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               entity      label correct\n",
       "0          dissection  PROCEDURE       1\n",
       "1            exchange    ANATOMY       0\n",
       "2               heart    ANATOMY       1\n",
       "3            bleeding  PROCEDURE       0\n",
       "4   knee arthroplasty    ANATOMY       1\n",
       "..                ...        ...     ...\n",
       "95                AST    SYMPTOM       1\n",
       "96             rhythm  PROCEDURE       1\n",
       "97             placed  PROCEDURE       1\n",
       "98   lateral pedicles    ANATOMY       1\n",
       "99             chills  PROCEDURE       1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To annotate entities for evaluation\n",
    "# from src.ner import annotate_entities\n",
    "# annotate_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17814579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom NER Manual Accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.read_csv(\"../data/custom_ner_evaluation/custom_ner_manual_evaluated.csv\")\n",
    "\n",
    "accuracy = df_eval[\"correct\"].mean()\n",
    "\n",
    "print(\"Custom NER Manual Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b821c22d",
   "metadata": {},
   "source": [
    "The custom medical NER model clearly outperforms the general-purpose spaCy NER on clinical text. While the baseline model only achieved around 30% accuracy in a manual evaluation of 100 random entities, the custom model improved this to about 45%. Most of the remaining errors are due to confusion between symptoms vs. diseases (e.g. “weakness”, “swelling”, “paresthesias”) and some cases where non-entities were labeled as entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ead6b",
   "metadata": {},
   "source": [
    "# 5. Investigate using an LLM-based NER classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bf6f827",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m model.to(device)\n\u001b[32m     16\u001b[39m results = []\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     18\u001b[39m     encoding = tokenizer(\n\u001b[32m     19\u001b[39m         text,\n\u001b[32m     20\u001b[39m         return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m         truncation=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     22\u001b[39m         padding=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     23\u001b[39m     ).to(device)\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:665\u001b[39m, in \u001b[36mtqdm.__new__\u001b[39m\u001b[34m(cls, *_, **__)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *_, **__):\n\u001b[32m    664\u001b[39m     instance = \u001b[38;5;28mobject\u001b[39m.\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# also constructs lock if non-existent\u001b[39;49;00m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_instances\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# create monitoring thread\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:111\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:104\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.acquire\u001b[39m\u001b[34m(self, *a, **k)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, *a, **k):\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.locks:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "local_path = \"../models/biomedical-ner-all\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(local_path)\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "results = []\n",
    "for text in tqdm(texts):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoding).logits\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=2)[0].cpu().numpy()\n",
    "    tokens = encoding.tokens()\n",
    "\n",
    "    results.append(list(zip(tokens, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3575d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "local_path = \"../models/biomedical-ner-all\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(local_path)\n",
    "\n",
    "nlp_clinical_ner_bert = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eb36021",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m results = []\n\u001b[32m      5\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      7\u001b[39m     ents = nlp_clinical_ner_bert(text, batch_size=\u001b[32m16\u001b[39m)\n\u001b[32m      8\u001b[39m     results.append([(e[\u001b[33m'\u001b[39m\u001b[33mword\u001b[39m\u001b[33m'\u001b[39m], e[\u001b[33m'\u001b[39m\u001b[33mentity_group\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m ents])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:665\u001b[39m, in \u001b[36mtqdm.__new__\u001b[39m\u001b[34m(cls, *_, **__)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *_, **__):\n\u001b[32m    664\u001b[39m     instance = \u001b[38;5;28mobject\u001b[39m.\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# also constructs lock if non-existent\u001b[39;49;00m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_instances\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# create monitoring thread\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:111\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:104\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.acquire\u001b[39m\u001b[34m(self, *a, **k)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, *a, **k):\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.locks:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "for text in tqdm(texts):\n",
    "    ents = nlp_clinical_ner_bert(text, batch_size=16)\n",
    "    results.append([(e['word'], e['entity_group']) for e in ents])\n",
    "end_time = time.time()\n",
    "print(f\"NER processing time: {end_time - start_time} seconds\")\n",
    "df['clinical_bert_ents'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f68b5843",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     10\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     12\u001b[39m     batch_output = nlp_clinical_ner_bert(batch)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m batch_output:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:665\u001b[39m, in \u001b[36mtqdm.__new__\u001b[39m\u001b[34m(cls, *_, **__)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *_, **__):\n\u001b[32m    664\u001b[39m     instance = \u001b[38;5;28mobject\u001b[39m.\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# also constructs lock if non-existent\u001b[39;49;00m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_instances\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# create monitoring thread\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:111\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/hello/lib/python3.11/site-packages/tqdm/std.py:104\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.acquire\u001b[39m\u001b[34m(self, *a, **k)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, *a, **k):\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.locks:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "texts = df[\"text\"].tolist()\n",
    "results = []\n",
    "\n",
    "batch_size = 16\n",
    "batches = [texts[i:i+batch_size] for i in range(0, len(texts), batch_size)]\n",
    "\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "start = time.time()\n",
    "for batch in tqdm(batches):\n",
    "    batch_output = nlp_clinical_ner_bert(batch)\n",
    "    for output in batch_output:\n",
    "        results.append([(e[\"word\"], e[\"entity_group\"]) for e in output])\n",
    "end = time.time()\n",
    "\n",
    "df[\"clinical_bert_ents\"] = results\n",
    "print(\"Total time:\", end - start)\n",
    "print(\"Average per document:\", (end - start) / len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "ent_counter = Counter()\n",
    "for ents in df['clinical_bert_ents']:\n",
    "    for _, label in ents:\n",
    "        ent_counter[label] += 1\n",
    "\n",
    "ent_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(52)\n",
    "all_custom_ents = []\n",
    "for ents in df[\"clinical_bert_ents\"]:\n",
    "    all_custom_ents.extend(ents)\n",
    "\n",
    "sample_ents = random.sample(all_custom_ents, 100)\n",
    "\n",
    "eval_df = pd.DataFrame(sample_ents, columns=[\"entity\", \"label\"])\n",
    "\n",
    "eval_df.to_csv(\"../data/LLM_based_NER_evaluation/LLM_based_ner_manual_eval.csv\", index=False)\n",
    "eval_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4676f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://huggingface.co/Helios9/BioMed_NER\n",
    "\n",
    "def merge_consecutive_entities(entities, text):\n",
    "    entities = sorted(entities, key=lambda x: x['start'])\n",
    "    merged_entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    for entity in entities:\n",
    "        if current_entity is None:\n",
    "            current_entity = entity\n",
    "        elif (\n",
    "            entity['entity_group'] == current_entity['entity_group'] and\n",
    "            (entity['start'] <= current_entity['end'])\n",
    "        ):\n",
    "            # Merge based on start and end positions in the text\n",
    "            current_entity['end'] = max(current_entity['end'], entity['end'])\n",
    "            current_entity['word'] = text[current_entity['start']:current_entity['end']]\n",
    "            current_entity['score'] = (current_entity['score'] + entity['score']) / 2  \n",
    "        else:\n",
    "            merged_entities.append(current_entity)\n",
    "            current_entity = entity\n",
    "    if current_entity:\n",
    "        merged_entities.append(current_entity)\n",
    "\n",
    "    return merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Helios9/BioMed_NER'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "nlp_clinical_ner_bert = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "results = []\n",
    "for text in tqdm(texts):\n",
    "    result = nlp_clinical_ner_bert(text)\n",
    "    final_result=merge_consecutive_entities(result,text)\n",
    "    results.append([(e['word'], e['entity_group']) for e in final_result])\n",
    "    \n",
    "df['clinical_bert_ents'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6de924",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d0e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
