{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb4e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/argilla/medical-domain/data/train-00000-of-00001-67e4e7207342a623.parquet\")\n",
    "\n",
    "def extract_label(pred):\n",
    "    if isinstance(pred, (list, np.ndarray)) and len(pred) > 0 and isinstance(pred[0], dict):\n",
    "        return pred[0].get(\"label\")\n",
    "    return None\n",
    "\n",
    "df['label'] = df['prediction'].apply(extract_label)\n",
    "df['text_length'] = df['metrics'].apply(lambda x: x.get('text_length') if isinstance(x, dict) else None)\n",
    "\n",
    "# drop empty columns\n",
    "df = df.drop(columns=['inputs', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'multi_label', 'explanation', 'metadata', 'status', 'event_timestamp', 'metrics'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4c114",
   "metadata": {},
   "source": [
    "# 1. Investigate which NER types appear (manual inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa36a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text'].sample(20).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a6c0b",
   "metadata": {},
   "source": [
    "After manually inspecting 20 randomly sampled clinical notes, the following types of named entities appear frequently and consistently throughout the dataset:\n",
    "\n",
    "Core Medical Entity Types\n",
    "1.\tDISEASE / CONDITION: \"fracture\", \"polycythemia vera\", \"pneumonia\", \"multiple sclerosis\", \"otitis media\"\n",
    "\n",
    "2.\tPROCEDURE / SURGERY: \"colonoscopy\", \"laparoscopy\", \"arthroscopy\", \"right middle lobectomy\", \"heart catheterization\"\n",
    "3.\tANATOMY / BODY PART: \"radius and ulna\", \"left shin\", \"rotator cuff\", \"middle lobe\", \"cervical spine\"\n",
    "4.\tMEDICATION: \"methadone\", \"aspirin prophylaxis\", \"prednisone\", \"amoxicillin\", \"Zithromax\"\n",
    "5.\tLAB VALUE / MEASUREMENT: \"CBC 41,900\", \"CRP 6.7\", \"BP 144/85\", \"weight 61.8 kg\", \"temperature 99.5°F\"\n",
    "6.\tSYMPTOM / FINDING: \"pain\", \"swelling\", \"wheezing\", \"fatigue\", \"rash\", \"tenderness\"\n",
    "\n",
    "Conclusion:\n",
    "The dataset is rich in medical terminology, with DISEASE, PROCEDURE, ANATOMY, MEDICATION, LAB_VALUE, and SYMPTOM being the most prominent NER categories. These will be used to define the custom medical NER schema in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79312682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pain': np.int64(2059),\n",
       "         'x-ray': np.int64(698),\n",
       "         'mri': np.int64(529),\n",
       "         'cancer': np.int64(464),\n",
       "         'biopsy': np.int64(437),\n",
       "         'swelling': np.int64(429),\n",
       "         'fracture': np.int64(404),\n",
       "         'ultrasound': np.int64(354),\n",
       "         'ct scan': np.int64(326),\n",
       "         'tumor': np.int64(325),\n",
       "         'aspirin': np.int64(315),\n",
       "         'pneumonia': np.int64(223),\n",
       "         'colonoscopy': np.int64(156),\n",
       "         'laparoscopy': np.int64(76),\n",
       "         'methadone': np.int64(32)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantitative support to manual inspection\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "keywords = [\"fracture\", \"pneumonia\", \"colonoscopy\", \"laparoscopy\", \"methadone\", \"aspirin\", \"pain\", \"swelling\",\"biopsy\", \"ultrasound\", \"mri\", \"ct scan\", \"x-ray\", \"tumor\", \"cancer\"]\n",
    "Counter({kw: df['text'].str.contains(kw, case=False).sum() for kw in keywords})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d34cc",
   "metadata": {},
   "source": [
    "# 2. Apply spaCy’s standard NER classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b050a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4966/4966 [01:44<00:00, 47.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER processing took 104.77 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import subprocess\n",
    "import sys\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "model_name = \"en_core_web_md\"\n",
    "try:\n",
    "    nlp = spacy.load(model_name)\n",
    "except OSError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", model_name])\n",
    "    nlp = spacy.load(model_name)\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "start_time = time.time()\n",
    "ents_list = []\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=32, n_process=multiprocessing.cpu_count()), total=len(texts)):\n",
    "    ents_list.append([(ent.text, ent.label_) for ent in doc.ents])\n",
    "end_time = time.time()\n",
    "print(f\"NER processing took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "df['spacy_ents'] = ents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570953c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacy_ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Iron deficiency anemia.,POSTOPERATIVE DIAGNOSIS:,  Diverticulosis.,PROCEDURE:,  Colonoscopy.,MEDICATIONS: , MAC.,PROCEDURE: , The Olympus pediatric variable colonoscope w...</td>\n",
       "      <td>[(Iron, ORG), (Diverticulosis, PERSON), (Colonoscopy, ORG), (MAC.,PROCEDURE, GPE), (Olympus, ORG), (retroflex, NORP), (Diverticulosis, PERSON), (2 years, DATE)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLINICAL INDICATION:  ,Normal stress test.,PROCEDURES PERFORMED:,1.  Left heart cath.,2.  Selective coronary angiography.,3.  LV gram.,4.  Right femoral arteriogram.,5.  Mynx closure device.,PROCE...</td>\n",
       "      <td>[(LV gram, PERSON), (Mynx, ORG), (2%, PERCENT), (6-French, QUANTITY), (6-French JL4, MONEY), (6-French 3DRC, QUANTITY), (6-French, QUANTITY), (Post LV gram, FAC), (Mynx, ORG), (LVEDP, ORG), (9, DA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FINDINGS:,Axial scans were performed from L1 to S2 and reformatted images were obtained in the sagittal and coronal planes.,Preliminary scout film demonstrates anterior end plate spondylosis at T1...</td>\n",
       "      <td>[(L1 to S2, FAC), (T11-12, ORG), (T12-L1.,L1-2, ORG), (4.6mm, QUANTITY), (AP, ORG), (#25).,L4-5, MONEY)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Blood loss anemia.,POSTOPERATIVE DIAGNOSES:,1.  Diverticulosis coli.,2.  Internal hemorrhoids.,3.  Poor prep.,PROCEDURE PERFORMED:,  Colonoscopy with photos.,ANESTHESIA: ...</td>\n",
       "      <td>[(DIAGNOSES:,1, ORG), (Diverticulosis, PERSON), (Conscious, ORG), (Anesthesia, PERSON), (85-year-old, DATE), (EGD, ORG), (the Endoscopy Suite, ORG), (the Anesthesia Department, ORG)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REASON FOR VISIT:  ,Elevated PSA with nocturia and occasional daytime frequency.,HISTORY: , A 68-year-old male with a history of frequency and some outlet obstructive issues along with irritative ...</td>\n",
       "      <td>[(nocturia, ORG), (68-year-old, DATE), (PSA, ORG), (PSA, ORG), (2004, DATE), (5.5, DATE), (2003, DATE), (Dr. X, PERSON), (1.6, CARDINAL), (Proscar, PERSON), (Proscar, PERSON), (greater than five y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  PREOPERATIVE DIAGNOSIS:,  Iron deficiency anemia.,POSTOPERATIVE DIAGNOSIS:,  Diverticulosis.,PROCEDURE:,  Colonoscopy.,MEDICATIONS: , MAC.,PROCEDURE: , The Olympus pediatric variable colonoscope w...   \n",
       "1  CLINICAL INDICATION:  ,Normal stress test.,PROCEDURES PERFORMED:,1.  Left heart cath.,2.  Selective coronary angiography.,3.  LV gram.,4.  Right femoral arteriogram.,5.  Mynx closure device.,PROCE...   \n",
       "2  FINDINGS:,Axial scans were performed from L1 to S2 and reformatted images were obtained in the sagittal and coronal planes.,Preliminary scout film demonstrates anterior end plate spondylosis at T1...   \n",
       "3  PREOPERATIVE DIAGNOSIS: , Blood loss anemia.,POSTOPERATIVE DIAGNOSES:,1.  Diverticulosis coli.,2.  Internal hemorrhoids.,3.  Poor prep.,PROCEDURE PERFORMED:,  Colonoscopy with photos.,ANESTHESIA: ...   \n",
       "4  REASON FOR VISIT:  ,Elevated PSA with nocturia and occasional daytime frequency.,HISTORY: , A 68-year-old male with a history of frequency and some outlet obstructive issues along with irritative ...   \n",
       "\n",
       "                                                                                                                                                                                                spacy_ents  \n",
       "0                                         [(Iron, ORG), (Diverticulosis, PERSON), (Colonoscopy, ORG), (MAC.,PROCEDURE, GPE), (Olympus, ORG), (retroflex, NORP), (Diverticulosis, PERSON), (2 years, DATE)]  \n",
       "1  [(LV gram, PERSON), (Mynx, ORG), (2%, PERCENT), (6-French, QUANTITY), (6-French JL4, MONEY), (6-French 3DRC, QUANTITY), (6-French, QUANTITY), (Post LV gram, FAC), (Mynx, ORG), (LVEDP, ORG), (9, DA...  \n",
       "2                                                                                                 [(L1 to S2, FAC), (T11-12, ORG), (T12-L1.,L1-2, ORG), (4.6mm, QUANTITY), (AP, ORG), (#25).,L4-5, MONEY)]  \n",
       "3                   [(DIAGNOSES:,1, ORG), (Diverticulosis, PERSON), (Conscious, ORG), (Anesthesia, PERSON), (85-year-old, DATE), (EGD, ORG), (the Endoscopy Suite, ORG), (the Anesthesia Department, ORG)]  \n",
       "4  [(nocturia, ORG), (68-year-old, DATE), (PSA, ORG), (PSA, ORG), (2004, DATE), (5.5, DATE), (2003, DATE), (Dr. X, PERSON), (1.6, CARDINAL), (Proscar, PERSON), (Proscar, PERSON), (greater than five y...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'spacy_ents']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81543ca7",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "spaCy's general English model is not specialized for clinical NER tasks. For example, \"Iron\" -> ORG, \"Diverticulosis\" -> PERSON, \"Colonoscopy\" -> ORG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52153540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ORG', 31211),\n",
       " ('CARDINAL', 28793),\n",
       " ('DATE', 19170),\n",
       " ('PERSON', 15137),\n",
       " ('QUANTITY', 10040),\n",
       " ('GPE', 4631),\n",
       " ('TIME', 4325),\n",
       " ('PRODUCT', 3739),\n",
       " ('ORDINAL', 3462),\n",
       " ('PERCENT', 3192),\n",
       " ('NORP', 2729),\n",
       " ('MONEY', 2283),\n",
       " ('LOC', 595),\n",
       " ('FAC', 540),\n",
       " ('LAW', 371),\n",
       " ('EVENT', 308),\n",
       " ('WORK_OF_ART', 194),\n",
       " ('LANGUAGE', 84)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute entity frequencies\n",
    "from collections import Counter\n",
    "\n",
    "ent_counter = Counter()\n",
    "for ents in df['spacy_ents']:\n",
    "    for _, label in ents:\n",
    "        ent_counter[label] += 1\n",
    "\n",
    "ent_counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79907d",
   "metadata": {},
   "source": [
    "# 3. Evaluate spaCy NER (automatic + manual)\n",
    "\n",
    "### 3.1 Manual Evaluation of spaCy NER (100 Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "187092e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacy_ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>[(16-year-old, DATE), (the Pediatric Endocrinology Department, ORG), (first, ORDINAL), (about 2004, DATE), (the Pediatric Endocrinology Department, ORG), (zero, CARDINAL), (Tijuana, GPE), (Mexico,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>[(25 mg, QUANTITY), (Demerol, ORG), (the IV Demerol, ORG), (25 mg, QUANTITY), (Phenergan IV, GPE), (7.5 mg, QUANTITY), (Digital, ORG), (P160, PRODUCT), (30 cm, QUANTITY), (five, CARDINAL), (One, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>[(Esophagogastroduodenoscopy, ORG), (Melena, PERSON), (GI, ORG), (IMPRESSION,1, ORG), (Repeat EGD, PERSON), (tomorrow, DATE), (morning, TIME), (ICU, ORG), (100, CARDINAL), (EGD, ORG), (An addition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>[(35-year-old, DATE), (the 30th of October 2008, DATE), (nine months, DATE), (approximately 14 to 18 hours, DATE), (the 31st of October, DATE), (Foley, PERSON), (the 1st of November 2008, DATE), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>[(Bronchoscopy, ORG), (Foley, PERSON), (Betadine, NORP), (Hemostasis, PERSON), (sixth, ORDINAL), (sixth, ORDINAL), (3 cm, QUANTITY), (#00, MONEY), (Potts, PERSON), (Direction, FAC), (000, MONEY), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                   spacy_ents\n",
       "3138  [(16-year-old, DATE), (the Pediatric Endocrinology Department, ORG), (first, ORDINAL), (about 2004, DATE), (the Pediatric Endocrinology Department, ORG), (zero, CARDINAL), (Tijuana, GPE), (Mexico,...\n",
       "1964  [(25 mg, QUANTITY), (Demerol, ORG), (the IV Demerol, ORG), (25 mg, QUANTITY), (Phenergan IV, GPE), (7.5 mg, QUANTITY), (Digital, ORG), (P160, PRODUCT), (30 cm, QUANTITY), (five, CARDINAL), (One, C...\n",
       "1344  [(Esophagogastroduodenoscopy, ORG), (Melena, PERSON), (GI, ORG), (IMPRESSION,1, ORG), (Repeat EGD, PERSON), (tomorrow, DATE), (morning, TIME), (ICU, ORG), (100, CARDINAL), (EGD, ORG), (An addition...\n",
       "2984  [(35-year-old, DATE), (the 30th of October 2008, DATE), (nine months, DATE), (approximately 14 to 18 hours, DATE), (the 31st of October, DATE), (Foley, PERSON), (the 1st of November 2008, DATE), (...\n",
       "4910  [(Bronchoscopy, ORG), (Foley, PERSON), (Betadine, NORP), (Hemostasis, PERSON), (sixth, ORDINAL), (sixth, ORDINAL), (3 cm, QUANTITY), (#00, MONEY), (Potts, PERSON), (Direction, FAC), (000, MONEY), ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(100, random_state=42)\n",
    "sample_df[['spacy_ents']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bd777",
   "metadata": {},
   "source": [
    "We sampled 100 random entities from the model output and evaluated whether each prediction is correct in the medical context.\n",
    "\n",
    "| Entity | spaCy Label | Correct? | Expected Medical Category | Comment |\n",
    "|--------|-------------|----------|----------------------------|---------|\n",
    "| Esophagogastroduodenoscopy | ORG | ❌ | PROCEDURE | Misread as organization |\n",
    "| Melena | PERSON | ❌ | SYMPTOM / FINDING | Disease labeled as person |\n",
    "| Demerol | ORG | ❌ | MEDICATION | Drug interpreted as an organization |\n",
    "| Betadine | NORP | ❌ | MEDICATION / ANTISEPTIC | Not a nationality/group |\n",
    "| CT Abdomen & Pelvis | ORG | ❌ | IMAGING PROCEDURE | Imaging test mislabeled |\n",
    "| Foley | PERSON | ❌ | DEVICE / CATHETER | Mistaken as a person |\n",
    "| L4–L5 | ORG | ❌ | ANATOMY | Vertebral level mislabeled |\n",
    "| 3.4 cm | QUANTITY | ✔️ | MEASUREMENT | Correct |\n",
    "| 12-mm trocar | QUANTITY | ✔️ | DEVICE SIZE | Acceptable |\n",
    "| 05/26/1999 | DATE | ✔️ | DATE | Correct |\n",
    "| Pediatric Endocrinology Dept | ORG | ✔️ | DEPARTMENT | Acceptable |\n",
    "| Tijuana | GPE | ✔️ | LOCATION | Correct |\n",
    "| Isovue-300 | LOC | ❌ | CONTRAST AGENT | Incorrect category |\n",
    "| ICU | ORG | ❌ | LOCATION / UNIT | Hospital units ≠ organizations |\n",
    "| Bronchoscopy | ORG | ❌ | PROCEDURE | Misread as organization |\n",
    "| Hemostasis | PERSON | ❌ | PROCEDURE / ACTION | Labeled as a person |\n",
    "| Potts | PERSON | ✔️ | SURGICAL INSTRUMENT | Label acceptable but misleading |\n",
    "| 100 mL | QUANTITY | ✔️ | DOSAGE/VOLUME | Correct |\n",
    "| 2.5 cm | QUANTITY | ✔️ | MEASUREMENT | Correct |\n",
    "| hemiscrotum | ORG | ❌ | ANATOMY | Body part labeled as ORG |\n",
    "| Electrocautery | PERSON | ❌ | PROCEDURE / DEVICE | Not a person |\n",
    "| 1.72 | CARDINAL | ✔️ | NUMERIC VALUE | OK |\n",
    "| Soft | PERSON | ❌ | EXAM FINDING | Not a person |\n",
    "| Hydrochlorothiazide | ORG | ❌ | MEDICATION | Drug mislabeled |\n",
    "| Lisinopril | ORG | ❌ | MEDICATION | Drug mislabeled |\n",
    "| Percocet | ORG | ❌ | MEDICATION | Drug mislabeled |\n",
    "| Nontender | PERSON | ❌ | EXAM FINDING | Not a person |\n",
    "| Marcaine | PERSON | ❌ | MEDICATION | Not a person |\n",
    "| Veress | PRODUCT | ✔️ | SURGICAL DEVICE | Acceptable |\n",
    "| 12-mm VersaStep | QUANTITY | ✔️ | DEVICE SIZE | OK |\n",
    "| Appendix | NORP | ❌ | ANATOMY | Not a nationality |\n",
    "| Endocatch | ORG | ❌ | SURGICAL DEVICE | Incorrect |\n",
    "| ABCD General Hospital | ORG | ✔️ | FACILITY | Correct |\n",
    "| X. | PERSON | ✔️ | PERSON | Correct |\n",
    "| 1% | PERCENT | ✔️ | MEASUREMENT | Correct |\n",
    "| Glenn | PERSON | ✔️ | PERSON/PROCEDURE | Acceptable |\n",
    "| Fontan | PERSON | ❌ | PROCEDURE | Misinterpreted as person |\n",
    "| Benadryl | ORG | ❌ | MEDICATION | Drug mislabeled |\n",
    "| 124 pounds | QUANTITY | ✔️ | WEIGHT | Correct |\n",
    "| 96/54 | CARDINAL | ✔️ | VITAL SIGN | spaCy lacks medical category |\n",
    "| Phacoemulsification | ORG | ❌ | PROCEDURE | Incorrect |\n",
    "| Silicone | ORG | ❌ | MATERIAL | Incorrect |\n",
    "| ABC Laboratories | ORG | ✔️ | COMPANY | Correct |\n",
    "| EKG | ORG | ❌ | PROCEDURE | Misclassified |\n",
    "| Jun. | PERSON | ❌ | DATE | Misread as a person |\n",
    "| Laparoscopic Roux-en-Y | PERSON | ❌ | PROCEDURE | Wrong label |\n",
    "| EEA | ORG | ❌ | SURGICAL DEVICE | Incorrect |\n",
    "| Ziac | PERSON | ❌ | MEDICATION | Wrong label |\n",
    "| Remeron | PERSON | ❌ | MEDICATION | Wrong label |\n",
    "| Salt Lake City | GPE | ✔️ | LOCATION | Correct |\n",
    "| Noncontrast CT | ORG | ❌ | IMAGING PROCEDURE | Incorrect |\n",
    "| Levaquin | PERSON | ❌ | MEDICATION | Incorrect |\n",
    "| Reglan | FAC | ❌ | MEDICATION | Incorrect |\n",
    "| Streptococcal | ORG | ❌ | DISEASE / ORGANISM | Incorrect |\n",
    "| thromboplastin | NORP | ❌ | LAB / PROTEIN | Not nationality |\n",
    "| Foley catheter | PERSON | ❌ | DEVICE | Wrong label |\n",
    "| Veress needle | PRODUCT | ✔️ | DEVICE | Correct |\n",
    "| 16-French | QUANTITY | ✔️ | DEVICE SIZE | Correct |\n",
    "| concha bullosa | PERSON | ❌ | ANATOMICAL FINDING | Wrong label |\n",
    "| ENT | ORG | ✔️ | SPECIALTY | Acceptable |\n",
    "| CT Abdomen & Pelvis W/WO | ORG | ❌ | IMAGING | Incorrect |\n",
    "| Powerade | PERSON | ❌ | SUBSTANCE | Not a person |\n",
    "| CPK | ORG | ❌ | LAB TEST | Incorrect |\n",
    "| Kawasaki | PERSON | ❌ | DISEASE | Wrong |\n",
    "| CRP | ORG | ❌ | LAB TEST | Wrong |\n",
    "| ESR | ORG | ❌ | LAB TEST | Wrong |\n",
    "| IVIG | ORG | ❌ | MEDICATION / IMMUNOTHERAPY | Wrong |\n",
    "| Echocardiogram | ORG | ❌ | IMAGING PROCEDURE | Wrong |\n",
    "| SMK | ORG | ✔️ | COMPANY / BRAND | Acceptable |\n",
    "| Depo-Medrol | PRODUCT | ✔️ | MEDICATION | Acceptable |\n",
    "| Coagulation | ORG | ❌ | LAB / PHYSIOLOGY | Wrong |\n",
    "| ERCP | ORG | ❌ | PROCEDURE | Wrong |\n",
    "| Medical Oncology | ORG | ✔️ | DEPARTMENT | Acceptable |\n",
    "| T7–T8 | PRODUCT | ❌ | ANATOMY | Wrong category |\n",
    "| Medtronic | ORG | ✔️ | DEVICE COMPANY | Correct |\n",
    "| Fluoroscopy | PERSON | ❌ | IMAGING PROCEDURE | Wrong |\n",
    "| T2–L2 | NORP | ❌ | ANATOMY | Not a nationality |\n",
    "| Jackson | PERSON | ✔️ | PERSON | Correct |\n",
    "| Thecal sac | ORG | ❌ | ANATOMY | Wrong |\n",
    "| 5.5 | CARDINAL | ✔️ | VALUE | Correct |\n",
    "| 20 mg | QUANTITY | ✔️ | DOSAGE | Correct |\n",
    "| 30 cm | QUANTITY | ✔️ | MEASUREMENT | Correct |\n",
    "| One | CARDINAL | ✔️ | NUMBER | Correct |\n",
    "| 000 | MONEY | ❌ | NONE | Misinterpreted as money |\n",
    "| Direction | FAC | ❌ | NONE | Wrong label |\n",
    "| Soft tissue | PERSON | ❌ | ANATOMY | Misinterpreted |\n",
    "| Renal | ORG | ❌ | ANATOMY / ADJECTIVE | Incorrect |\n",
    "| 47-year-old | DATE | ❌ | AGE | Age ≠ Date |\n",
    "| daily | DATE | ❌ | FREQUENCY | Not a date |\n",
    "| five days | DATE | ✔️ | TEMPORAL | Acceptable |\n",
    "| Appendectomy | ORG | ❌ | PROCEDURE | Wrong |\n",
    "| Benign tumor | ORG | ❌ | DIAGNOSIS | Wrong |\n",
    "| L5-S1 | ORG | ❌ | ANATOMY | Wrong |\n",
    "| Marcaine injection | PERSON | ❌ | PROCEDURE | Wrong |\n",
    "| Hemostasis achieved | PERSON | ❌ | PROCEDURE STEP | Wrong |\n",
    "| 10 cm incision | QUANTITY | ✔️ | MEASUREMENT | Correct |\n",
    "| 200 mg | QUANTITY | ✔️ | DOSAGE | Correct |\n",
    "| 50-year-old | DATE | ❌ | AGE | Wrong label |\n",
    "| Many years | DATE | ✔️ | TEMPORAL | Correct |\n",
    "| 14 months | DATE | ✔️ | AGE | Acceptable |\n",
    "\n",
    "**What spaCy Does Well**\n",
    "- Dates and temporal expressions (e.g., “05/26/1999”, “five days”)\n",
    "- Quantities and measurements (cm, mg, %, weights)\n",
    "- Person names (e.g., \"Jackson\")\n",
    "- Some organizations and locations\n",
    "\n",
    "**What spaCy Does Poorly**\n",
    "- Medications often -> ORG or PERSON  \n",
    "- Procedures often -> ORG  \n",
    "- Anatomy -> ORG, NORP, or PERSON  \n",
    "- Devices -> PERSON  \n",
    "- Lab tests -> ORG  \n",
    "- Diseases -> PERSON  \n",
    "- No medical categories (MEDICATION, PROCEDURE, ANATOMY, LAB, etc.)\n",
    "\n",
    "**Overall Quality (100 entities)**\n",
    "- Correct: ~30%\n",
    "- Incorrect: ~70%\n",
    "\n",
    "spaCy’s general English model performs poorly on clinical notes.\n",
    "It lacks domain knowledge and mislabels most medical entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd0601",
   "metadata": {},
   "source": [
    "### 3.2 Automatic Evaluation\n",
    "\n",
    "Since we do not have gold standard NER annotations, we cannot do automatic evaluation like precision/recall/F1. Custom annotations will be created in the next steps for proper evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c832ac",
   "metadata": {},
   "source": [
    "# 4. Extend NER with custom entity types (NER Annotator)\n",
    "\n",
    "To overcome the limitations of spaCy’s general-purpose NER model on clinical text, we created a custom medical NER system using six domain-specific labels:\n",
    "\n",
    "DISEASE, MEDICATION, SYMPTOM, PROCEDURE, ANATOMY, LAB_VALUE\n",
    "\n",
    "### 4.1 Manual Annotation Using NER Annotator\n",
    "\n",
    "We manually annotated clinical reports using the online NER Annotator tool. https://arunmozhi.in/ner-annotator/\n",
    "\n",
    "The resulting annotations.json file contains:\n",
    "- ~12 annotated documents\n",
    "- Several thousand labeled entities across all classes\n",
    "- Clean character-based spans compatible with spaCy\n",
    "\n",
    "Example annotation:\n",
    "```json\n",
    "{\n",
    "  \"classes\": [\"DISEASE\", \"MEDICATION\", \"SYMPTOM\", ...],\n",
    "  \"annotations\": [\n",
    "    [\"<text 1>\", {\"entities\": [[start, end, label], ...]}],\n",
    "    [\"<text 2>\", {\"entities\": [...]}],\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbb0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = df['text'].sample(10, random_state=42)\n",
    "sample_texts.to_csv('../data/samples/to_annotate.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df719aa",
   "metadata": {},
   "source": [
    "### 4.2 Converting JSON to spaCy’s DocBin Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f0e7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.ner import train_custom_ner, load_annotated_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3cb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this JSON into spaCy’s DocBin format:\n",
    "db = load_annotated_json(\"../data/annotated/annotations.json\")\n",
    "db.to_disk(\"train.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e824c01",
   "metadata": {},
   "source": [
    "### 4.2 Training the Custom NER Model\n",
    "\n",
    "We extended the NER label space by creating six new domain specific medical entity types\n",
    "(DISEASE, MEDICATION, SYMPTOM, PROCEDURE, ANATOMY, LAB_VALUE).\n",
    "To train a model on these labels, we used a blank spaCy model and trained a new NER component from scratch.\n",
    "This means the resulting model replaces spaCy’s general-purpose NER schema (PERSON, ORG, DATE, etc.) with our\n",
    "custom medical schema.\n",
    "\n",
    "This approach avoids catastrophic forgetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b8264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Losses: {'ner': np.float32(7615.732)}\n",
      "Iteration 2, Losses: {'ner': np.float32(6619.6504)}\n",
      "Iteration 3, Losses: {'ner': np.float32(3833.589)}\n",
      "Iteration 4, Losses: {'ner': np.float32(1372.6106)}\n",
      "Iteration 5, Losses: {'ner': np.float32(1374.5095)}\n",
      "Iteration 6, Losses: {'ner': np.float32(1229.4198)}\n",
      "Iteration 7, Losses: {'ner': np.float32(1146.8406)}\n",
      "Iteration 8, Losses: {'ner': np.float32(1109.8662)}\n",
      "Iteration 9, Losses: {'ner': np.float32(1071.0986)}\n",
      "Iteration 10, Losses: {'ner': np.float32(1051.5828)}\n",
      "Iteration 11, Losses: {'ner': np.float32(968.34503)}\n",
      "Iteration 12, Losses: {'ner': np.float32(921.83594)}\n",
      "Iteration 13, Losses: {'ner': np.float32(924.1687)}\n",
      "Iteration 14, Losses: {'ner': np.float32(875.2458)}\n",
      "Iteration 15, Losses: {'ner': np.float32(821.63007)}\n",
      "Iteration 16, Losses: {'ner': np.float32(813.93677)}\n",
      "Iteration 17, Losses: {'ner': np.float32(767.02747)}\n",
      "Iteration 18, Losses: {'ner': np.float32(733.31744)}\n",
      "Iteration 19, Losses: {'ner': np.float32(709.97186)}\n",
      "Iteration 20, Losses: {'ner': np.float32(679.573)}\n",
      "Iteration 21, Losses: {'ner': np.float32(659.90826)}\n",
      "Iteration 22, Losses: {'ner': np.float32(622.0745)}\n",
      "Iteration 23, Losses: {'ner': np.float32(590.6679)}\n",
      "Iteration 24, Losses: {'ner': np.float32(602.03015)}\n",
      "Iteration 25, Losses: {'ner': np.float32(564.4365)}\n",
      "Iteration 26, Losses: {'ner': np.float32(528.7557)}\n",
      "Iteration 27, Losses: {'ner': np.float32(503.41367)}\n",
      "Iteration 28, Losses: {'ner': np.float32(481.00977)}\n",
      "Iteration 29, Losses: {'ner': np.float32(449.20657)}\n",
      "Iteration 30, Losses: {'ner': np.float32(427.5424)}\n",
      "Saved model at: ../data/models/custom_ner\n"
     ]
    }
   ],
   "source": [
    "# 6 custom labels and train a blank eglish model from scratch\n",
    "labels = [\"DISEASE\", \"MEDICATION\", \"SYMPTOM\", \"PROCEDURE\", \"ANATOMY\", \"LAB_VALUE\"]\n",
    "\n",
    "output_dir = \"../data/models/custom_ner\"\n",
    "\n",
    "nlp_custom = train_custom_ner(\"train.spacy\",output_dir, labels, n_iter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4eca0c",
   "metadata": {},
   "source": [
    "### 4.4 Applying the Custom Model to All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7d9bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4966/4966 [00:36<00:00, 137.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER processing time: 36.045693159103394 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import time\n",
    "\n",
    "nlp_custom = spacy.load(\"../data/models/custom_ner\")\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "start_time = time.time()\n",
    "ents_list = []\n",
    "for doc in tqdm(nlp_custom.pipe(texts, batch_size=32, n_process=multiprocessing.cpu_count()), total=len(texts)):\n",
    "    ents_list.append([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"NER processing time: {end_time - start_time} seconds\")\n",
    "df['custom_ents'] = ents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89bec9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ANATOMY', 57430),\n",
       " ('PROCEDURE', 28363),\n",
       " ('DISEASE', 22019),\n",
       " ('SYMPTOM', 1899),\n",
       " ('MEDICATION', 1797),\n",
       " ('LAB_VALUE', 562)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute entity frequencies\n",
    "from collections import Counter\n",
    "\n",
    "ent_counter = Counter()\n",
    "for ents in df['custom_ents']:\n",
    "    for _, label in ents:\n",
    "        ent_counter[label] += 1\n",
    "\n",
    "ent_counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2f261",
   "metadata": {},
   "source": [
    "**Note**\n",
    "- surgical and radiology notes have a lot of ANATOMY and PROCEDURE entities.\n",
    "- MEDICATION is comparatively rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39e89de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>custom_ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>REASON FOR CONSULTATION: , Thyroid mass diagnosed as papillary carcinoma.,HISTORY OF PRESENT ILLNESS:  ,The patient is a 16-year-old young lady, who was referred from the Pediatric Endocrinology D...</td>\n",
       "      <td>[(Thyroid, ANATOMY), (thyroid, ANATOMY), (papillary carcinoma, DISEASE), (hypothyroidism, DISEASE), (lesion, DISEASE), (head, ANATOMY), (endocrinopathy, DISEASE), (surgical procedures, ANATOMY), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Prior history of neoplastic polyps.,POSTOPERATIVE DIAGNOSIS:,  Small rectal polyps/removed and fulgurated.,PREMEDICATIONS:,  Prior to the colonoscopy, the patient complai...</td>\n",
       "      <td>[(neoplastic polyps, DISEASE), (rectal polyps, DISEASE), (colonoscopy, ANATOMY), (headache, DISEASE), (25 mg, LAB_VALUE), (Demerol, MEDICATION), (Demerol, MEDICATION), (nausea, MEDICATION), (Phene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>PROCEDURE PERFORMED: , Esophagogastroduodenoscopy performed in the emergency department.,INDICATION: , Melena, acute upper GI bleed, anemia, and history of cirrhosis and varices.,FINAL IMPRESSION,...</td>\n",
       "      <td>[(Esophagogastroduodenoscopy, ANATOMY), (Melena, DISEASE), (acute upper GI bleed, DISEASE), (anemia, DISEASE), (cirrhosis, DISEASE), (varices, DISEASE), (stomach, ANATOMY), (fundus, ANATOMY), (End...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , The patient is a 35-year-old woman who reports that on the 30th of October 2008, she had a rupture of her membranes at nine months of pregnancy, and was admitted to h...</td>\n",
       "      <td>[(epidural, MEDICATION), (anesthetic, DISEASE), (epidural, ANATOMY), (14 to 18 hours, LAB_VALUE), (epidural, ANATOMY), (epidural, ANATOMY), (extremely sleepy, DISEASE), (delivered, PROCEDURE), (Ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:  ,Carcinoma of the left upper lobe.,PROCEDURES PERFORMED:,1.  Bronchoscopy with aspiration.,2.  Left upper lobectomy.,PROCEDURE DETAILS:  ,With patient in supine position u...</td>\n",
       "      <td>[(Carcinoma, DISEASE), (Bronchoscopy, PROCEDURE), (aspiration, PROCEDURE), (Left upper lobectomy, PROCEDURE), (placed, PROCEDURE), (examine, PROCEDURE), (carina, ANATOMY), (carina, ANATOMY), (lobe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         text  \\\n",
       "3138  REASON FOR CONSULTATION: , Thyroid mass diagnosed as papillary carcinoma.,HISTORY OF PRESENT ILLNESS:  ,The patient is a 16-year-old young lady, who was referred from the Pediatric Endocrinology D...   \n",
       "1964  PREOPERATIVE DIAGNOSIS:,  Prior history of neoplastic polyps.,POSTOPERATIVE DIAGNOSIS:,  Small rectal polyps/removed and fulgurated.,PREMEDICATIONS:,  Prior to the colonoscopy, the patient complai...   \n",
       "1344  PROCEDURE PERFORMED: , Esophagogastroduodenoscopy performed in the emergency department.,INDICATION: , Melena, acute upper GI bleed, anemia, and history of cirrhosis and varices.,FINAL IMPRESSION,...   \n",
       "2984  HISTORY OF PRESENT ILLNESS: , The patient is a 35-year-old woman who reports that on the 30th of October 2008, she had a rupture of her membranes at nine months of pregnancy, and was admitted to h...   \n",
       "4910  PREOPERATIVE DIAGNOSIS:  ,Carcinoma of the left upper lobe.,PROCEDURES PERFORMED:,1.  Bronchoscopy with aspiration.,2.  Left upper lobectomy.,PROCEDURE DETAILS:  ,With patient in supine position u...   \n",
       "\n",
       "                                                                                                                                                                                                  custom_ents  \n",
       "3138  [(Thyroid, ANATOMY), (thyroid, ANATOMY), (papillary carcinoma, DISEASE), (hypothyroidism, DISEASE), (lesion, DISEASE), (head, ANATOMY), (endocrinopathy, DISEASE), (surgical procedures, ANATOMY), (...  \n",
       "1964  [(neoplastic polyps, DISEASE), (rectal polyps, DISEASE), (colonoscopy, ANATOMY), (headache, DISEASE), (25 mg, LAB_VALUE), (Demerol, MEDICATION), (Demerol, MEDICATION), (nausea, MEDICATION), (Phene...  \n",
       "1344  [(Esophagogastroduodenoscopy, ANATOMY), (Melena, DISEASE), (acute upper GI bleed, DISEASE), (anemia, DISEASE), (cirrhosis, DISEASE), (varices, DISEASE), (stomach, ANATOMY), (fundus, ANATOMY), (End...  \n",
       "2984  [(epidural, MEDICATION), (anesthetic, DISEASE), (epidural, ANATOMY), (14 to 18 hours, LAB_VALUE), (epidural, ANATOMY), (epidural, ANATOMY), (extremely sleepy, DISEASE), (delivered, PROCEDURE), (Ce...  \n",
       "4910  [(Carcinoma, DISEASE), (Bronchoscopy, PROCEDURE), (aspiration, PROCEDURE), (Left upper lobectomy, PROCEDURE), (placed, PROCEDURE), (examine, PROCEDURE), (carina, ANATOMY), (carina, ANATOMY), (lobe...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(100, random_state=42)\n",
    "sample_df[['text', 'custom_ents']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ade6d8",
   "metadata": {},
   "source": [
    "### 4.5 Evaluate 100 random custom entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ddbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "all_custom_ents = []\n",
    "for ents in df[\"custom_ents\"]:\n",
    "    all_custom_ents.extend(ents)\n",
    "\n",
    "sample_ents = random.sample(all_custom_ents, 100)\n",
    "\n",
    "eval_df = pd.DataFrame(sample_ents, columns=[\"entity\", \"label\"])\n",
    "\n",
    "# To save for manual evaluation\n",
    "# eval_df.to_csv(\"../data/custom_ner_evaluation/custom_ner_manual_eval.csv\", index=False)\n",
    "# eval_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To annotate entities for evaluation\n",
    "# from src.ner import annotate_entities\n",
    "# annotate_entities(\"../data/custom_ner_evaluation/custom_ner_manual_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17814579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom NER Manual Accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.read_csv(\"../data/custom_ner_evaluation/custom_ner_manual_eval.csv\")\n",
    "\n",
    "accuracy = df_eval[\"correct\"].mean()\n",
    "\n",
    "print(\"Custom NER Manual Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b821c22d",
   "metadata": {},
   "source": [
    "The custom medical NER model clearly outperforms the general-purpose spaCy NER on clinical text. While the baseline model only achieved around 30% accuracy in a manual evaluation of 100 random entities, the custom model improved this to about 45%. Most of the remaining errors are due to confusion between symptoms vs. diseases (e.g. “weakness”, “swelling”, “paresthesias”) and some cases where non-entities were labeled as entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ead6b",
   "metadata": {},
   "source": [
    "# 5. Investigate using an LLM-based NER classifier\n",
    "\n",
    "### 5.1 Generate NER Predictions Using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3575d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists at ../models/biomedical-ner-all, loading from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "local_path = \"../models/biomedical-ner-all\"\n",
    "hf_model_id = \"d4data/biomedical-ner-all\"\n",
    "\n",
    "try:\n",
    "    if not os.path.isdir(local_path):\n",
    "        print(f\"Downloading model from Hugging Face: {hf_model_id}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(hf_model_id, cache_dir=local_path)\n",
    "        model = AutoModelForTokenClassification.from_pretrained(hf_model_id, cache_dir=local_path)\n",
    "    else:\n",
    "        print(f\"Model already exists at {local_path}, loading from disk.\") \n",
    "        tokenizer = AutoTokenizer.from_pretrained(local_path)\n",
    "        model = AutoModelForTokenClassification.from_pretrained(local_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading model: {e}\")\n",
    "\n",
    "nlp_clinical_ner_bert = pipeline(\n",
    "    task=\"ner\", # or \"token-classification\"\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\" # merges wordpiece tokens into whole entities/words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1844b8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0ada49030a42d18d38e5935c6bc5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing biomedical NER:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processing time: 234.99s\n",
      "Avg time per document: 0.0473s\n"
     ]
    }
   ],
   "source": [
    "texts = df[\"text\"].tolist()\n",
    "batch_size = 8  # safe for CPU, increase if GPU available\n",
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]\n",
    "for batch in tqdm(batches, desc=\"Processing biomedical NER\"):\n",
    "    batch_output = nlp_clinical_ner_bert(batch)  # now batching is actually used\n",
    "    # convert HuggingFace output into (entity, label) format\n",
    "    for doc_out in batch_output:\n",
    "        results.append([(e[\"word\"], e[\"entity_group\"]) for e in doc_out])\n",
    "end = time.time()\n",
    "print(f\"Total processing time: {end - start:.2f}s\")\n",
    "print(f\"Avg time per document: {(end - start)/len(texts):.4f}s\")\n",
    "df[\"clinical_bert_ents\"] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f61fc216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Biological_structure', 43321),\n",
       " ('Sign_symptom', 37765),\n",
       " ('Therapeutic_procedure', 29608),\n",
       " ('Detailed_description', 28105),\n",
       " ('Diagnostic_procedure', 22932),\n",
       " ('Medication', 14631),\n",
       " ('Lab_value', 12118),\n",
       " ('Disease_disorder', 9228),\n",
       " ('Dosage', 5534),\n",
       " ('Clinical_event', 4679),\n",
       " ('Nonbiological_location', 4616),\n",
       " ('History', 3915),\n",
       " ('Age', 3028),\n",
       " ('Coreference', 2774),\n",
       " ('Severity', 2752),\n",
       " ('Sex', 2643),\n",
       " ('Duration', 2614),\n",
       " ('Date', 2138),\n",
       " ('Distance', 1729),\n",
       " ('Subject', 1618),\n",
       " ('Activity', 1525),\n",
       " ('Time', 1212),\n",
       " ('Administration', 1127),\n",
       " ('Personal_background', 950),\n",
       " ('Family_history', 629),\n",
       " ('Frequency', 589),\n",
       " ('Area', 558),\n",
       " ('Occupation', 360),\n",
       " ('Other_entity', 243),\n",
       " ('Volume', 223),\n",
       " ('Quantitative_concept', 208),\n",
       " ('Outcome', 184),\n",
       " ('Color', 163),\n",
       " ('Shape', 56),\n",
       " ('Texture', 47),\n",
       " ('Other_event', 38),\n",
       " ('Qualitative_concept', 18),\n",
       " ('Height', 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "ent_counter = Counter()\n",
    "for ents in df['clinical_bert_ents']:\n",
    "    for _, label in ents:\n",
    "        ent_counter[label] += 1\n",
    "\n",
    "ent_counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08157df",
   "metadata": {},
   "source": [
    "### 5.2 Manual Evaluation of LLM-based NER (100 Entities)\n",
    "\n",
    "We removed some subword fragments so that only full tokens are evaluated. We also mapped Hugging Face labels to our six medical labels for consistency during evaluation. All entities that cannot be mapped are discarded, and exactly 100 entities are randomly sampled for manual evaluation. Then the overall as well as per-label accuracy are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8544da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove subword fragments starting with \"##\"\n",
    "def is_subword(token):\n",
    "    return token.startswith(\"##\")\n",
    "\n",
    "cleaned_ents = []\n",
    "for ents in df[\"clinical_bert_ents\"]:\n",
    "    for e, label in ents:\n",
    "        if not is_subword(e):\n",
    "            cleaned_ents.append((e, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89f8fead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "      <th>mapped_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weight</td>\n",
       "      <td>Sign_symptom</td>\n",
       "      <td>SYMPTOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bone invasion</td>\n",
       "      <td>Sign_symptom</td>\n",
       "      <td>SYMPTOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ob</td>\n",
       "      <td>Biological_structure</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub</td>\n",
       "      <td>Biological_structure</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>position</td>\n",
       "      <td>Therapeutic_procedure</td>\n",
       "      <td>PROCEDURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>posterior talofib</td>\n",
       "      <td>Biological_structure</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>solution</td>\n",
       "      <td>Medication</td>\n",
       "      <td>MEDICATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ke</td>\n",
       "      <td>Disease_disorder</td>\n",
       "      <td>DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>toes</td>\n",
       "      <td>Biological_structure</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>negative</td>\n",
       "      <td>Lab_value</td>\n",
       "      <td>LAB_VALUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>steroid</td>\n",
       "      <td>Medication</td>\n",
       "      <td>MEDICATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inflammation</td>\n",
       "      <td>Sign_symptom</td>\n",
       "      <td>SYMPTOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chest</td>\n",
       "      <td>Biological_structure</td>\n",
       "      <td>ANATOMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>normal</td>\n",
       "      <td>Lab_value</td>\n",
       "      <td>LAB_VALUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>af</td>\n",
       "      <td>Medication</td>\n",
       "      <td>MEDICATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spinal fusion</td>\n",
       "      <td>Therapeutic_procedure</td>\n",
       "      <td>PROCEDURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>coronary artery disease</td>\n",
       "      <td>Disease_disorder</td>\n",
       "      <td>DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rev</td>\n",
       "      <td>Sign_symptom</td>\n",
       "      <td>SYMPTOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bunion deformity</td>\n",
       "      <td>Sign_symptom</td>\n",
       "      <td>SYMPTOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lactulose</td>\n",
       "      <td>Medication</td>\n",
       "      <td>MEDICATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     entity                  label mapped_label\n",
       "0                    weight           Sign_symptom      SYMPTOM\n",
       "1             bone invasion           Sign_symptom      SYMPTOM\n",
       "2                        ob   Biological_structure      ANATOMY\n",
       "3                       sub   Biological_structure      ANATOMY\n",
       "4                  position  Therapeutic_procedure    PROCEDURE\n",
       "5         posterior talofib   Biological_structure      ANATOMY\n",
       "6                  solution             Medication   MEDICATION\n",
       "7                        ke       Disease_disorder      DISEASE\n",
       "8                      toes   Biological_structure      ANATOMY\n",
       "9                  negative              Lab_value    LAB_VALUE\n",
       "10                  steroid             Medication   MEDICATION\n",
       "11             inflammation           Sign_symptom      SYMPTOM\n",
       "12                    chest   Biological_structure      ANATOMY\n",
       "13                   normal              Lab_value    LAB_VALUE\n",
       "14                       af             Medication   MEDICATION\n",
       "15            spinal fusion  Therapeutic_procedure    PROCEDURE\n",
       "16  coronary artery disease       Disease_disorder      DISEASE\n",
       "17                      rev           Sign_symptom      SYMPTOM\n",
       "18         bunion deformity           Sign_symptom      SYMPTOM\n",
       "19                lactulose             Medication   MEDICATION"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(52)\n",
    "\n",
    "sample_ents = random.sample(cleaned_ents, 200)\n",
    "eval_df = pd.DataFrame(sample_ents, columns=[\"entity\", \"label\"])\n",
    "\n",
    "label_map = {\n",
    "    \"Disease_disorder\": \"DISEASE\",\n",
    "    \"Medication\": \"MEDICATION\",\n",
    "    \"Sign_symptom\": \"SYMPTOM\",\n",
    "    \"Therapeutic_procedure\": \"PROCEDURE\",\n",
    "    \"Biological_structure\": \"ANATOMY\",\n",
    "    \"Lab_value\": \"LAB_VALUE\",\n",
    "}\n",
    "\n",
    "eval_df[\"mapped_label\"] = eval_df[\"label\"].map(label_map).fillna(\"OTHER\")\n",
    "eval_df = eval_df[eval_df[\"mapped_label\"] != \"OTHER\"]\n",
    "eval_df = eval_df.sample(100, random_state=42).reset_index(drop=True)\n",
    "eval_df = eval_df.reset_index(drop=True)\n",
    "\n",
    "eval_df.to_csv(\"../data/LLM_based_NER_evaluation/LLM_based_ner_manual_eval.csv\", index=False)\n",
    "eval_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To annotate entities for evaluation\n",
    "# from src.ner import annotate_entities\n",
    "# annotate_entities(\"../data/LLM_based_NER_evaluation/LLM_based_ner_manual_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "104d0e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall manual accuracy: 0.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mapped_label\n",
       "LAB_VALUE     0.636364\n",
       "ANATOMY       0.629630\n",
       "DISEASE       0.571429\n",
       "MEDICATION    0.571429\n",
       "SYMPTOM       0.517241\n",
       "PROCEDURE     0.250000\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.read_csv(\"../data/LLM_based_NER_evaluation/temp.csv\")\n",
    "\n",
    "accuracy = df_eval[\"correct\"].mean()\n",
    "per_label_acc = df_eval.groupby(\"mapped_label\")[\"correct\"].mean().sort_values(ascending=False)\n",
    "print(\"Overall manual accuracy:\", accuracy)\n",
    "per_label_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2439d71",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "Accuracy of 54% shows a clear improvement compared to the general spaCy model but remains far from reliable clinical performance. The strongest categories were LAB_VALUE (64%), ANATOMY (63%), and DISEASE / MEDICATION (both ~57%), indicating that the model handles lab terms, anatomy, and common medical conditions reasonably well. \n",
    "\n",
    "Performance dropped for SYMPTOM (52%), and PROCEDURE performed worst at 25%, showing that the model struggles most with surgical and procedural terminology. This pattern suggests that the biomedical model captures static medical vocabulary better than action- or procedure-related expressions, and that further domain-specific fine-tuning or a larger annotated dataset would be required for robust performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f53e8c",
   "metadata": {},
   "source": [
    "# 6. Describe how NER type information could help in other NLP use cases\n",
    "\n",
    "NER converts free text into structured, typed information (e.g., DISEASE, MEDICATION, PROCEDURE), which makes it easier for other NLP systems to work with clinical documents. In summarization, typed entities help highlight what is medically relevant instead of treating all words the same. In information retrieval, NER allows queries such as _\"show notes containing DISEASE = diabetes and MEDICATION = metformin\"_, making search results more focused. NER types also support tasks like linking symptoms to diagnoses, assigning ICD codes, building patient timelines, or checking records for missing or inconsistent information. By adding structure to medical text, NER helps downstream applications become more accurate and easier to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57fc66e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
